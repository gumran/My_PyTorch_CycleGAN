{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"},{"sourceId":6897716,"sourceType":"datasetVersion","datasetId":3962269}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torchvision.transforms as tt\nimport torch\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import seaborn as sns\nfrom PIL import Image\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T17:12:27.706638Z","iopub.execute_input":"2023-11-22T17:12:27.706951Z","iopub.status.idle":"2023-11-22T17:12:31.471778Z","shell.execute_reply.started":"2023-11-22T17:12:27.706925Z","shell.execute_reply":"2023-11-22T17:12:31.471035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"photos = []\ntransform = tt.ToTensor()\nnames = random.sample(os.listdir('/kaggle/input/gan-getting-started/photo_jpg'), 300)\nfor f in names:\n    img = Image.open('/kaggle/input/gan-getting-started/photo_jpg/' + f)\n    tensor = transform(img).unsqueeze(0).to('cuda')\n    #tensor = tensor.permute((1, 2, 0))\n    photos.append(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T16:52:28.045334Z","iopub.execute_input":"2023-11-22T16:52:28.046394Z","iopub.status.idle":"2023-11-22T16:52:33.180368Z","shell.execute_reply.started":"2023-11-22T16:52:28.046338Z","shell.execute_reply":"2023-11-22T16:52:33.179466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet = []\ntransform = tt.ToTensor()\nfor f in os.listdir('/kaggle/input/gan-getting-started/monet_jpg'):\n    img = Image.open('/kaggle/input/gan-getting-started/monet_jpg/' + f)\n    tensor = transform(img).unsqueeze(0).to('cuda')\n    #tensor = tensor.permute((1, 2, 0))\n    monet.append(tensor)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T16:52:35.203498Z","iopub.execute_input":"2023-11-22T16:52:35.203865Z","iopub.status.idle":"2023-11-22T16:52:36.961027Z","shell.execute_reply.started":"2023-11-22T16:52:35.203837Z","shell.execute_reply":"2023-11-22T16:52:36.960001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Downsample(nn.Module):\n    def __init__(self, in_channels, out_channels, size, apply_instancenorm=True):\n        super(Downsample, self).__init__()\n\n        self.conv = nn.Conv2d(in_channels, out_channels, size, stride=2, padding=1, bias=False)\n        self.apply_instancenorm = apply_instancenorm\n\n        if apply_instancenorm:\n            self.instance_norm = nn.InstanceNorm2d(out_channels, affine=False)\n        \n        self.leaky_relu = nn.LeakyReLU(0.2, inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        if self.apply_instancenorm:\n            x = self.instance_norm(x)\n        x = self.leaky_relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-22T17:12:35.228598Z","iopub.execute_input":"2023-11-22T17:12:35.229060Z","iopub.status.idle":"2023-11-22T17:12:35.236657Z","shell.execute_reply.started":"2023-11-22T17:12:35.229028Z","shell.execute_reply":"2023-11-22T17:12:35.235518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Upsample(nn.Module):\n    def __init__(self, in_channels, out_channels, size, apply_dropout=False):\n        super(Upsample, self).__init__()\n\n        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, size, stride=2, padding=1, output_padding=0, bias=False)\n        self.apply_dropout = apply_dropout\n        self.instance_norm = nn.InstanceNorm2d(out_channels, affine=False)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.conv_transpose(x)\n        x = self.instance_norm(x)\n        \n        if self.apply_dropout:\n            x = self.dropout(x)\n        \n        x = self.relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-22T17:12:37.206425Z","iopub.execute_input":"2023-11-22T17:12:37.207128Z","iopub.status.idle":"2023-11-22T17:12:37.214079Z","shell.execute_reply.started":"2023-11-22T17:12:37.207096Z","shell.execute_reply":"2023-11-22T17:12:37.213142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.down_stack = nn.ModuleList([\n            Downsample(3, 64, 4, apply_instancenorm=False),  # (bs, 128, 128, 64)\n            Downsample(64, 128, 4),  # (bs, 64, 64, 128)\n            Downsample(128, 256, 4),  # (bs, 32, 32, 256)\n            Downsample(256, 512, 4),  # (bs, 16, 16, 512)\n            Downsample(512, 512, 4),  # (bs, 8, 8, 512)\n            Downsample(512, 512, 4),  # (bs, 4, 4, 512)\n            Downsample(512, 512, 4),  # (bs, 2, 2, 512)\n            Downsample(512, 512, 4, apply_instancenorm=False)  # (bs, 1, 1, 512)\n        ])\n\n        self.up_stack = nn.ModuleList([\n            Upsample(512, 512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n            Upsample(1024, 512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n            Upsample(1024, 512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n            Upsample(1024, 512, 4),  # (bs, 16, 16, 1024)\n            Upsample(1024, 256, 4),  # (bs, 32, 32, 512)\n            Upsample(512, 128, 4),  # (bs, 64, 64, 256)\n            Upsample(256, 64, 4)  # (bs, 128, 128, 128)\n        ])\n\n        self.last = nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1)\n        self.tanh = nn.Tanh()\n    def forward(self, x):\n        skips = []\n        for down in self.down_stack:\n            x = down(x)\n            skips.append(x)\n\n        skips = reversed(skips[:-1])\n\n        for up, skip in zip(self.up_stack, skips):\n            x = up(x)\n            x = torch.cat([x, skip], dim=1)\n\n        x = self.last(x)\n        x = self.tanh(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-22T17:12:39.149383Z","iopub.execute_input":"2023-11-22T17:12:39.149765Z","iopub.status.idle":"2023-11-22T17:12:39.162825Z","shell.execute_reply.started":"2023-11-22T17:12:39.149733Z","shell.execute_reply":"2023-11-22T17:12:39.161763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Discriminator = nn.Sequential(\n    Downsample(3, 64, 4, False), # (bs, 128, 128, 64)\n    Downsample(64, 128, 4), # (bs, 64, 64, 128)\n    Downsample(128, 256, 4), # (bs, 32, 32, 256)\n    nn.ZeroPad2d(1), # (bs, 34, 34, 256)\n    nn.Conv2d(256, 512, 4, stride=1, padding=0, bias=False), # (bs, 31, 31, 512)\n    nn.InstanceNorm2d(512, affine=False),\n    nn.LeakyReLU(),\n    nn.ZeroPad2d(1),  # (bs, 33, 33, 512)\n    nn.Conv2d(512, 1, 4, stride=1),\n    #nn.Sigmoid()\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T17:12:41.396765Z","iopub.execute_input":"2023-11-22T17:12:41.397221Z","iopub.status.idle":"2023-11-22T17:12:41.445960Z","shell.execute_reply.started":"2023-11-22T17:12:41.397187Z","shell.execute_reply":"2023-11-22T17:12:41.445249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_generator = Generator().to('cuda') # transforms photos to Monet-esque paintings\nphoto_generator = Generator().to('cuda') # transforms Monet paintings to be more like photos\n\nmonet_discriminator = Discriminator.to('cuda') # differentiates real Monet paintings and generated Monet paintings\nphoto_discriminator = Discriminator.to('cuda') # differentiates real photos and generated photos","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:19:00.323264Z","iopub.execute_input":"2023-11-22T15:19:00.323546Z","iopub.status.idle":"2023-11-22T15:19:01.338370Z","shell.execute_reply.started":"2023-11-22T15:19:00.323524Z","shell.execute_reply":"2023-11-22T15:19:01.337540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = CycleGAN(monet_generator, photo_generator, monet_discriminator, photo_discriminator)\n\noptimizer_mg = torch.optim.Adam(monet_generator.parameters(), lr=0.001, )#betas=(0.5, 0.999))\noptimizer_pg = torch.optim.Adam(photo_generator.parameters(), lr=0.001, )#betas=(0.5, 0.999))\noptimizer_md = torch.optim.Adam(monet_discriminator.parameters(), lr=0.001, )#betas=(0.5, 0.999))\noptimizer_pd = torch.optim.Adam(photo_discriminator.parameters(), lr=0.001, )#betas=(0.5, 0.999))\n\ncriterion = nn.MSELoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:19:01.339417Z","iopub.execute_input":"2023-11-22T15:19:01.339701Z","iopub.status.idle":"2023-11-22T15:19:01.346257Z","shell.execute_reply.started":"2023-11-22T15:19:01.339676Z","shell.execute_reply":"2023-11-22T15:19:01.345371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(40):\n    monet_generator.train()\n    photo_generator.train()\n    monet_discriminator.train()\n    photo_discriminator.train()\n    print(f'Epoch {epoch + 1}')\n    monet_epoch_losses = []\n    disc_epoch_losses = []\n    for i in tqdm(range(300)):\n        real_photo = photos[i]\n        real_monet = monet[i]\n    #real_photo, real_monet = batch\n        optimizer_md.zero_grad()\n        optimizer_pd.zero_grad()\n        optimizer_mg.zero_grad()\n        optimizer_pg.zero_grad()\n\n        fake_monet = monet_generator(real_photo)\n        fake_photo = photo_generator(real_monet)\n\n        disc_real_monet = monet_discriminator(real_monet)\n        disc_fake_monet = monet_discriminator(fake_monet)\n\n        disc_real_photo = photo_discriminator(real_photo)\n        disc_fake_photo = photo_discriminator(fake_photo)\n\n        cycled_photo = photo_generator(fake_monet)\n        cycled_monet = monet_generator(fake_photo)\n\n        same_monet = monet_generator(real_monet)\n        same_photo = photo_generator(real_photo)\n\n        monet_discriminator_loss = 0.5 * criterion(disc_real_monet, torch.ones_like(disc_real_monet)) + 0.5 * criterion(disc_fake_monet, torch.zeros_like(disc_fake_monet))\n        \n\n        photo_discriminator_loss = 0.5 * criterion(disc_real_photo, torch.ones_like(disc_real_photo)) + 0.5 * criterion(disc_fake_photo, torch.zeros_like(disc_fake_photo))\n\n        cycle_loss = torch.abs(cycled_photo - real_photo).mean() + torch.abs(cycled_monet - real_monet).mean()\n\n        #monet_identity_loss = torch.abs(real_monet - same_monet).mean()\n        monet_generator_loss = criterion(disc_fake_monet, torch.ones_like(disc_fake_monet))\n        full_mg_loss = monet_generator_loss + cycle_loss #+ monet_identity_loss\n        \n        \n        #photo_identity_loss = torch.abs(real_photo - same_photo).mean()\n\n        photo_generator_loss = criterion(disc_fake_photo, torch.ones_like(disc_fake_photo))\n        full_pg_loss = photo_generator_loss + cycle_loss #+ photo_identity_loss\n        \n        \n        full_mg_loss.backward(retain_graph = True)\n        optimizer_mg.step()\n        \n        full_pg_loss.backward(retain_graph = True)\n        optimizer_pg.step()\n        \n        monet_discriminator_loss.backward(retain_graph = True)\n        optimizer_md.step()\n        \n        photo_discriminator_loss.backward(retain_graph = True)\n        optimizer_pd.step()\n        \n        k = monet_generator_loss.item()\n        monet_epoch_losses.append(k)\n        l = monet_discriminator_loss.item()\n        disc_epoch_losses.append(l)\n        print('Monet generator loss:', sum(monet_epoch_losses) / len(monet_epoch_losses),'Monet discriminator loss:', sum(disc_epoch_losses) / len(disc_epoch_losses), end ='\\r')\n    monet_generator.eval()\n    test = random.choice(photos)\n    out = monet_generator(test)\n    plt.imshow(test.squeeze(0).permute((1,2,0)).cpu().detach().numpy())\n    plt.show()\n    plt.imshow(out.squeeze(0).permute((1,2,0)).cpu().detach().numpy())\n    plt.show()\n    #print('Monet generator loss:', sum(monet_epoch_losses) / len(monet_epoch_losses))\n    #monet_epoch_loss = np.mean(monet_epoch_losses)\n    #print(f'Epoch {epoch + 1} Monet generator loss:', monet_epoch_loss)\n    \n    \n    #fake_monet, cycled_photo, fake_photo, cycled_monet, same_monet, same_photo, disc_real_monet, disc_real_photo, disc_fake_monet, disc_fake_photo = model(batch)\n    \n                                                                                                                    ","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:48:52.770453Z","iopub.execute_input":"2023-11-22T15:48:52.770814Z","iopub.status.idle":"2023-11-22T16:31:56.779027Z","shell.execute_reply.started":"2023-11-22T15:48:52.770786Z","shell.execute_reply":"2023-11-22T16:31:56.778152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(monet_generator, 'model2')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:30:41.401197Z","iopub.execute_input":"2023-11-23T06:30:41.402102Z","iopub.status.idle":"2023-11-23T06:30:54.096949Z","shell.execute_reply.started":"2023-11-23T06:30:41.402047Z","shell.execute_reply":"2023-11-23T06:30:54.095894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n#!gdown 15N3WHOQjYFxK-ovG-5CjV2mt76YOTd30","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:30:56.544850Z","iopub.execute_input":"2023-11-23T06:30:56.545193Z","iopub.status.idle":"2023-11-23T06:30:56.804169Z","shell.execute_reply.started":"2023-11-23T06:30:56.545165Z","shell.execute_reply":"2023-11-23T06:30:56.803310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_photos = []\ntransform = tt.ToTensor()\nfor f in tqdm(os.listdir('/kaggle/input/gan-getting-started/photo_jpg')):\n    img = Image.open('/kaggle/input/gan-getting-started/photo_jpg/' + f)\n    tensor = transform(img).unsqueeze(0).to('cuda')\n    #tensor = tensor.permute((1, 2, 0))\n    all_photos.append(tensor)\n    \n#do the inference on google colab","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:34:49.705238Z","iopub.execute_input":"2023-11-23T06:34:49.705613Z","iopub.status.idle":"2023-11-23T06:34:49.712819Z","shell.execute_reply.started":"2023-11-23T06:34:49.705585Z","shell.execute_reply":"2023-11-23T06:34:49.711615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown 1FumiaE5HDXx44hD1RRNVq90DQZjGmJuy #load the results","metadata":{"execution":{"iopub.status.busy":"2023-11-23T06:31:00.878513Z","iopub.execute_input":"2023-11-23T06:31:00.879361Z","iopub.status.idle":"2023-11-23T06:31:04.761034Z","shell.execute_reply.started":"2023-11-23T06:31:00.879327Z","shell.execute_reply":"2023-11-23T06:31:04.760042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(monet_generator, 'model2')","metadata":{"execution":{"iopub.status.busy":"2023-11-22T16:46:36.640639Z","iopub.execute_input":"2023-11-22T16:46:36.641541Z","iopub.status.idle":"2023-11-22T16:46:37.001668Z","shell.execute_reply.started":"2023-11-22T16:46:36.641505Z","shell.execute_reply":"2023-11-22T16:46:37.000698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}